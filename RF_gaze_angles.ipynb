{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "637f4fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9527777777777777\n",
      "Random forest               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87        53\n",
      "           1       0.97      0.97      0.97        74\n",
      "           2       1.00      0.98      0.99        51\n",
      "           3       0.89      0.93      0.91        54\n",
      "           4       0.97      1.00      0.98        63\n",
      "           5       0.98      0.97      0.98        65\n",
      "\n",
      "    accuracy                           0.95       360\n",
      "   macro avg       0.95      0.95      0.95       360\n",
      "weighted avg       0.95      0.95      0.95       360\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nparam_grid = {\\n    \\'n_estimators\\': [100, 200, 300, 400], \\n    \\'max_depth\\': [10, 20, 30, 40],        \\n    \\'min_samples_split\\': [2, 5, 10, 15], \\n    \\'min_samples_leaf\\': [1, 2, 4, 8],    \\n}\\n\\nclf = RandomForestClassifier(random_state=42)\\n\\ngrid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, n_jobs=-1)\\n\\ngrid_search.fit(X_train, y_train)\\n\\nbest_params = grid_search.best_params_\\nbest_estimator = grid_search.best_estimator_\\n\\nprint(\"Best Parameters:\", best_params)\\n\\nprint(\"Best Estimator:\", best_estimator)\\n\\ny_pred = best_estimator.predict(X_test)\\n\\naccuracy = accuracy_score(y_test, y_pred)\\nreport = classification_report(y_test, y_pred)\\n\\nprint(f\\'Accuracy: {accuracy}\\')\\nprint(\"Random Forest\", report)\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest model with gaze angles\n",
    "\n",
    "import numpy as np\n",
    "from scipy.stats import skew,kurtosis\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split,cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.integrate import trapz \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def extract_shape_features(data):\n",
    "    features = []\n",
    "    for i in range(data.shape[0]):\n",
    "        signal = data[i, :]\n",
    "        duration = len(signal)\n",
    "        peak_amplitude = np.max(signal)\n",
    "        valley_amplitude = np.min(signal)\n",
    "        mean_amplitude = np.mean(signal)\n",
    "        time_to_peak = np.argmax(signal)\n",
    "        time_to_valley = np.argmin(signal)\n",
    "        zero_crossings = np.where(np.diff(np.sign(signal)))[0]\n",
    "        zero_crossing_rate = len(zero_crossings) / duration\n",
    "        \n",
    "        signal_slope = np.gradient(signal)\n",
    "        rise_time = np.where(signal >= peak_amplitude)[0][0]\n",
    "        fall_time = duration - np.where(signal[::-1] >= peak_amplitude)[0][0]\n",
    "        signal_curvature = np.gradient(signal_slope)\n",
    "        inflection_points = np.where(np.diff(np.sign(signal_curvature)))[0]\n",
    "        \n",
    "        crest_factor = peak_amplitude / np.sqrt(np.mean(np.square(signal)))\n",
    "\n",
    "        skew_val = skew(signal)\n",
    "        kurt_val = kurtosis(signal)\n",
    "        # Additional features (modify or add more as needed)\n",
    "        std_deviation = np.std(signal)\n",
    "        variance = np.var(signal)\n",
    "        median = np.median(signal)\n",
    "        min_to_max_ratio = valley_amplitude / peak_amplitude\n",
    "        mean_abs_deviation = np.mean(np.abs(signal - mean_amplitude))\n",
    "        area_under_curve = trapz(signal)\n",
    "        \n",
    "        # Add features to the list\n",
    "        features.append([peak_amplitude, valley_amplitude, \n",
    "                         time_to_peak,time_to_valley, rise_time, fall_time,\n",
    "                         len(inflection_points), crest_factor, skew_val, kurt_val,\n",
    "                         std_deviation, variance, median, min_to_max_ratio, mean_abs_deviation])\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        eog_signal = np.loadtxt(file)\n",
    "        return eog_signal\n",
    "    \n",
    "\n",
    "double = pd.read_csv('C:/Users/PC/Desktop/new_signal_double.csv')\n",
    "down = pd.read_csv('C:/Users/PC/Desktop/new_signal_down.csv')\n",
    "right = pd.read_csv('C:/Users/PC/Desktop/new_signal_right.csv')\n",
    "left = pd.read_csv('C:/Users/PC/Desktop/new_signal_left.csv')\n",
    "up = pd.read_csv('C:/Users/PC/Desktop/new_signal_up.csv')\n",
    "none = pd.read_csv('C:/Users/PC/Desktop/bos_resampled.csv')\n",
    "\n",
    "double_signal =[]\n",
    "down_signal =[]\n",
    "right_signal =[]\n",
    "left_signal =[]\n",
    "up_signal =[]\n",
    "none_signal = []\n",
    "\n",
    "double_signal.append(double)\n",
    "down_signal.append(down)\n",
    "right_signal.append(right)\n",
    "left_signal.append(left)\n",
    "up_signal.append(up)\n",
    "none_signal.append(none)\n",
    "\n",
    "size_double = np.array(double_signal)\n",
    "size_down = np.array(down_signal)\n",
    "size_up = np.array(up_signal)\n",
    "size_left = np.array(left_signal)\n",
    "size_right = np.array(right_signal)\n",
    "size_none = np.array(none_signal)\n",
    "\n",
    "size_double = size_double.reshape(size_double.shape[1],size_double.shape[2])\n",
    "size_down = size_down.reshape(size_down.shape[1],size_down.shape[2])\n",
    "size_up = size_up.reshape(size_up.shape[1],size_up.shape[2])\n",
    "size_left = size_left.reshape(size_left.shape[1],size_left.shape[2])\n",
    "size_right = size_right.reshape(size_right.shape[1],size_right.shape[2])\n",
    "size_none = size_none.reshape(size_none.shape[1],size_none.shape[2])\n",
    "\n",
    "# RIGHT FEATURES\n",
    "right_gaze_angles = read_txt_file(\"C:/Users/PC/vscoe/right_gaze.txt\")\n",
    "right_features = extract_shape_features(size_right)\n",
    "right_gaze_angles = np.array(right_gaze_angles)\n",
    "right_features_combined = np.column_stack((right_features, right_gaze_angles))\n",
    "\n",
    "# LEFT FEATURES\n",
    "left_gaze_angles = read_txt_file(\"C:/Users/PC/vscoe/left_gaze.txt\")\n",
    "left_features = extract_shape_features(size_left)\n",
    "left_gaze_angles = np.array(left_gaze_angles)\n",
    "left_features_combined = np.column_stack((left_features, left_gaze_angles))\n",
    "\n",
    "# UP FEATURES\n",
    "up_gaze_angles = read_txt_file(\"C:/Users/PC/vscoe/up_gaze.txt\")\n",
    "up_features = extract_shape_features(size_up)\n",
    "up_gaze_angles = np.array(up_gaze_angles)\n",
    "up_features_combined = np.column_stack((up_features, up_gaze_angles))\n",
    "\n",
    "# DOWN FEATURES\n",
    "down_gaze_angles = read_txt_file(\"C:/Users/PC/vscoe/down_gaze.txt\")\n",
    "down_features = extract_shape_features(size_down)\n",
    "down_gaze_angles = np.array(down_gaze_angles)\n",
    "down_features_combined = np.column_stack((down_features, down_gaze_angles))\n",
    "\n",
    "# DOUBLE FEATURES\n",
    "double_gaze_angles = read_txt_file(\"C:/Users/PC/vscoe/double_gaze.txt\")\n",
    "double_features = extract_shape_features(size_double)\n",
    "double_gaze_angles = np.array(double_gaze_angles)\n",
    "double_features_combined = np.column_stack((double_features, double_gaze_angles))\n",
    "\n",
    "# NONE FEATURES\n",
    "none_gaze_angles = read_txt_file(\"C:/Users/PC/vscoe/none_gaze.txt\")\n",
    "none_features = extract_shape_features(size_none)\n",
    "none_gaze_angles = np.array(none_gaze_angles)\n",
    "none_features_combined = np.column_stack((none_features, none_gaze_angles))\n",
    "\n",
    "all_features_combined = np.concatenate((right_features_combined, left_features_combined,up_features_combined,down_features_combined,double_features_combined,none_features_combined), axis=0)\n",
    "all_features_wo_gaze = np.concatenate((right_features,left_features,up_features,down_features,double_features,none_features), axis=0)\n",
    "\n",
    "data_order = [0] * 300 + [1] * 300 + [2] * 300 + [3] * 300 + [4] * 300 + [5] * 298\n",
    "y_train = np.array(data_order)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_features_combined,y_train_encoded, test_size=0.2,random_state=42)\n",
    "\n",
    "clf2 = RandomForestClassifier(n_estimators=400, max_depth=30,min_samples_split=2,min_samples_leaf=1,random_state=42)\n",
    "\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf2.predict(X_test)\n",
    "\n",
    "joblib.dump(clf2, 'pkl_doc/RF_model_EOG_waveform_new.pkl')\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(\"Random forest\",report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5fe3143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "# make predictions with shape features\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pywt\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.integrate import trapz\n",
    "\n",
    "def extract_shape_features(data):\n",
    "    features = []\n",
    "    for i in range(data.shape[0]):\n",
    "        signal = data[i, :]\n",
    "        duration = len(signal)\n",
    "        peak_amplitude = np.max(signal)\n",
    "        valley_amplitude = np.min(signal)\n",
    "        mean_amplitude = np.mean(signal)\n",
    "        time_to_peak = np.argmax(signal)\n",
    "        zero_crossings = np.where(np.diff(np.sign(signal)))[0]\n",
    "        zero_crossing_rate = len(zero_crossings) / duration\n",
    "\n",
    "        signal_slope = np.gradient(signal)\n",
    "\n",
    "        rise_time = np.where(signal >= peak_amplitude)[0][0]\n",
    "        fall_time = duration - np.where(signal[::-1] >= peak_amplitude)[0][0]\n",
    "        signal_curvature = np.gradient(signal_slope)\n",
    "        inflection_points = np.where(np.diff(np.sign(signal_curvature)))[0]\n",
    "        \n",
    "        crest_factor = peak_amplitude / np.sqrt(np.mean(np.square(signal)))\n",
    "\n",
    "        skew_val = skew(signal)\n",
    "        kurt_val = kurtosis(signal)\n",
    "        \n",
    "        std_deviation = np.std(signal)\n",
    "        variance = np.var(signal)\n",
    "        median = np.median(signal)\n",
    "        min_to_max_ratio = valley_amplitude / peak_amplitude\n",
    "        mean_abs_deviation = np.mean(np.abs(signal - mean_amplitude))\n",
    "        area_under_curve = trapz(signal)\n",
    "        \n",
    "        features.append([peak_amplitude, valley_amplitude, \n",
    "                         time_to_peak,rise_time,fall_time,\n",
    "                         len(inflection_points), crest_factor, skew_val, kurt_val,\n",
    "                         std_deviation, variance, median, min_to_max_ratio, mean_abs_deviation,area_under_curve])\n",
    "\n",
    "    return np.array(features)\n",
    "\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        eog_signal = np.loadtxt(file)\n",
    "        return eog_signal\n",
    "\n",
    "\n",
    "eog_signal = read_txt_file(\"C:/Users/PC/EOG/maho_txt/maho right.txt\")\n",
    "\n",
    "loaded_model = joblib.load('pkl_doc/RF_model_EOG_waveform_new.pkl')\n",
    "\n",
    "normalized_dizi = eog_signal.reshape(1,eog_signal.shape[0])\n",
    "\n",
    "X = extract_shape_features(normalized_dizi)\n",
    "features_combined = np.column_stack((X, 44))\n",
    "input_data = features_combined\n",
    "\n",
    "predictions = loaded_model.predict(input_data)\n",
    "\n",
    "print(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eda7b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
